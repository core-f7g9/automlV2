import math, time

# Bedrock embedding client
brt = boto3.client("bedrock-runtime", region_name=boto3.Session().region_name)


def extract_embeddings_from_payload(payload):
    """
    Make Cohere v4 responses explicit and fail early if structure is unexpected.
    Expected shapes:
      - {"response_type": "embeddings_floats", "embeddings": [[...], ...]}
      - {"response_type": "embeddings_by_type", "embeddings": {"float": [[...], ...]}}
      - Rare: {"embeddings": [{"embedding": [...]}]}
    """
    if "embeddings" not in payload:
        raise ValueError(f"Missing 'embeddings' in payload keys={list(payload.keys())}")

    emb = payload["embeddings"]

    # If dict keyed by embedding type
    if isinstance(emb, dict):
        for key in ("float", "embedding", "embeddings", "int8", "uint8", "binary", "ubinary"):
            if key in emb:
                emb = emb[key]
                break

    # If list of dicts with "embedding" key
    if isinstance(emb, list) and emb and isinstance(emb[0], dict) and "embedding" in emb[0]:
        emb = [row["embedding"] for row in emb]

    # Final check: must be list/tuple of vectors (numbers)
    if not isinstance(emb, list):
        raise ValueError(f"Unexpected embeddings type: {type(emb)} value sample={emb}")
    if emb and isinstance(emb[0], str):
        # Catch the bad case early instead of corrupting the list
        raise ValueError(f"Embeddings came back as strings (sample={emb[:1]}), cannot use.")

    return emb


def embed_batch_cohere(texts):
    # Hard truncate within the batch for safety/throughput
    texts = [t[:MAX_TEXT_CHARS] for t in texts]
    body = {
        "texts": texts,
        "input_type": "search_document",
        "truncate": TRUNCATE_STRATEGY,  # RIGHT truncation on long inputs
        # "output_dimension": 1536,     # uncomment to force vector size (256/512/1024/1536)
        # "embedding_types": ["float"], # default is float; can request int8/uint8/binary/ubinary
    }
    last_err = None
    for attempt in range(1, EMBED_MAX_RETRIES + 1):
        try:
            resp = brt.invoke_model(
                modelId=EMBED_MODEL_ID,
                body=json.dumps(body),
                accept="application/json",
                contentType="application/json",
            )
            payload = json.loads(resp["body"].read())
            emb = extract_embeddings_from_payload(payload)
            if len(emb) != len(texts):
                raise ValueError(f"Embedding count mismatch: got {len(emb)} for batch {len(texts)}")
            return emb
        except Exception as e:
            last_err = e
            sleep_s = EMBED_BACKOFF_BASE ** attempt
            time.sleep(sleep_s)
    raise RuntimeError(f"Embedding failed after {EMBED_MAX_RETRIES} retries: {last_err}")


def embed_single(text):
    return embed_batch_cohere([text])[0]


embeddings = []
num_batches = math.ceil(len(texts_ready) / BATCH_SIZE)

for i in tqdm(range(num_batches), desc="Embedding with Bedrock"):
    start = i * BATCH_SIZE
    end = min(start + BATCH_SIZE, len(texts_ready))
    batch = texts_ready[start:end]
    batch_embeddings = embed_batch_cohere(batch)
    embeddings.extend(batch_embeddings)

# Validate/repair embeddings -> float32
cleaned = [None] * len(embeddings)
bad = []
for idx, emb in enumerate(embeddings):
    try:
        cleaned[idx] = np.asarray(emb, dtype=np.float32)
    except Exception as e:
        bad.append((idx, e))

if bad:
    print(f"Retrying {len(bad)} embeddings individually due to parse errors...")
    for idx, err in bad:
        try:
            re_emb = embed_single(texts_ready[idx])
            cleaned[idx] = np.asarray(re_emb, dtype=np.float32)
        except Exception as e2:
            raise RuntimeError(f"Embedding parse failed at global index {idx}: {err}; retry error: {e2}")

embeddings = np.vstack(cleaned)

print(f"Embeddings shape: {embeddings.shape} (records x dimensions)")
assert embeddings.shape[0] == len(df), "Mismatch between embeddings and rows"
