%%writefile preprocess.py
import argparse
import os
import pandas as pd
import numpy as np

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--targets", type=str, help="Comma separated list of target columns")
    parser.add_argument("--features", type=str, help="Comma separated list of input features")
    args, _ = parser.parse_known_args()

    # Parse arguments
    target_cols = args.targets.split(",")
    input_features = args.features.split(",")
    
    print(f"Reading data... Targets: {target_cols}, Features: {input_features}")

    # Read input data (SageMaker mounts input data to /opt/ml/processing/input)
    input_data_path = "/opt/ml/processing/input/data.csv"
    
    # Load dataset (Chunksize usage recommended for 2M+ rows if memory is tight, but 2M usually fits in pandas)
    df = pd.read_csv(input_data_path)
    
    # Process each target dynamically
    for target in target_cols:
        print(f"Processing dataset for target: {target}")
        
        # Select only the relevant features + current target
        # We explicitly exclude other targets to prevent data leakage
        cols_to_keep = input_features + [target]
        
        # Filter dataframe
        df_target = df[cols_to_keep].copy()
        
        # Drop rows where the target is missing (AutoML requires clean targets)
        df_target.dropna(subset=[target], inplace=True)
        
        # Save to specific output directory for this target
        # SageMaker Processing outputs are mapped from /opt/ml/processing/output/
        output_dir = f"/opt/ml/processing/output/{target}"
        os.makedirs(output_dir, exist_ok=True)
        
        output_path = os.path.join(output_dir, "train.csv")
        df_target.to_csv(output_path, index=False, header=True)
        
        print(f"Saved {len(df_target)} records to {output_path}")