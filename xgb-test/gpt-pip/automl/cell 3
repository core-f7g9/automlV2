# -------------------------------
# Pipeline parameters
# -------------------------------
AUTOML_MAX_CANDIDATES = ParameterInteger("AutoMLMaxCandidates", default_value=15)
AUTOML_TOTAL_RUNTIME  = ParameterInteger("AutoMLTotalRuntimeSec", default_value=3600)  # per target (seconds)

# -------------------------------
# PREP STEP
# -------------------------------
prep_processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1,
    sagemaker_session=pipeline_session,
)

prep_prefix = f"{PROJECT_PREFIX}/prep_for_autopilot"

step_prep = ProcessingStep(
    name="PrepForAutopilot",
    processor=prep_processor,
    inputs=[
        ProcessingInput(
            input_name="raw",
            source=INPUT_S3,
            destination="/opt/ml/processing/input",
        )
    ],
    outputs=[
        ProcessingOutput(
            output_name="prep",
            source="/opt/ml/processing/output",
            destination=f"s3://{BUCKET}/{prep_prefix}",
        )
    ],
    code="prep_for_autopilot.py",
    job_arguments=[
        "--input_dir", "/opt/ml/processing/input",
        "--targets", json.dumps(TARGET_COLS),
        "--input_features", json.dumps(INPUT_FEATURES),
        "--output_dir", "/opt/ml/processing/output",
        "--random_state", "42",
    ],
)

prep_uri = step_prep.properties.ProcessingOutputConfig.Outputs["prep"].S3Output.S3Uri

# -------------------------------
# AutoML retry policy (internal errors)
# -------------------------------
from sagemaker.workflow.retry import StepRetryPolicy, StepExceptionTypeEnum

retry_policies = [
    StepRetryPolicy(
        exception_types=[
            StepExceptionTypeEnum.SERVICE_FAULT,
            StepExceptionTypeEnum.THROTTLING,
        ],
        max_attempts=5,
        interval_seconds=30,
        backoff_rate=2.0,
    )
]

# -------------------------------
# AutoML TRAIN (per target)
# -------------------------------
automl_steps = []

for tgt in TARGET_COLS:
    tgt_safe = safe_name(tgt.lower(), max_len=22)
    project_safe = safe_name(PROJECT_PREFIX.lower(), max_len=18)

    automl_output = f"s3://{BUCKET}/{PROJECT_PREFIX}/automl-output/{tgt_safe}"

    # Training data produced by prep step
    train_s3 = Join(on="/", values=[prep_uri, tgt, "train.csv"])

    automl = AutoML(
        role=role,
        target_attribute_name=tgt,
        output_path=automl_output,
        mode="ENSEMBLING",  # REQUIRED for AutoMLStep
        problem_type="MulticlassClassification",
        job_objective={"MetricName": "Accuracy"},
        max_candidates=AUTOML_MAX_CANDIDATES,
        total_job_runtime_in_seconds=AUTOML_TOTAL_RUNTIME,
        base_job_name=f"{project_safe}-{tgt_safe}",  # keep it short & safe
        sagemaker_session=pipeline_session,
    )

    # IMPORTANT: training channel ONLY (no validation channel for AutoMLStep robustness)
    automl_inputs = [
        AutoMLInput(
            inputs=train_s3,
            target_attribute_name=tgt,
            channel_type="training",
            content_type="text/csv;header=present",
        )
    ]

    step_args = automl.fit(inputs=automl_inputs)

    step_automl = AutoMLStep(
        name=f"AutoML-{tgt_safe}",     # no underscores
        step_args=step_args,
        depends_on=[step_prep],
        retry_policies=[retry_policy],
    )

    automl_steps.append(step_automl)

# -------------------------------
# PIPELINE (train-only)
# -------------------------------
pipeline = Pipeline(
    name=safe_name(f"{PROJECT_PREFIX}-train-only", max_len=80),
    parameters=[AUTOML_MAX_CANDIDATES, AUTOML_TOTAL_RUNTIME],
    steps=[step_prep] + automl_steps,
    sagemaker_session=pipeline_session,
)

pipeline.upsert(role_arn=role)
print("âœ… Pipeline upserted:", pipeline.name)
