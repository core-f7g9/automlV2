# Pipeline parameters (override at execution time if needed)
param_input_s3 = ParameterString(name="InputS3", default_value=INPUT_S3)
param_output_base = ParameterString(name="OutputBase", default_value=OUTPUT_BASE)

param_val_frac = ParameterFloat(name="ValFrac", default_value=0.2)
param_max_candidates = ParameterInteger(name="MaxCandidates", default_value=20)

# Processing infra
sklearn_processor = SKLearnProcessor(
    framework_version="1.2-1",
    role=role,
    instance_type="ml.m5.4xlarge",
    instance_count=1,
    sagemaker_session=pipeline_session,
)

steps = []

for t in TARGET_COLS:
    # Unique per execution + target
    exec_id = ExecutionVariables.PIPELINE_EXECUTION_ID

    # Processing outputs (S3)
    proc_train_s3 = Join(on="/", values=[param_output_base, exec_id, t, "split", "train"])
    proc_val_s3   = Join(on="/", values=[param_output_base, exec_id, t, "split", "validation"])
    automl_out_s3  = Join(on="/", values=[param_output_base, exec_id, t, "automl"])

    # 1) ProcessingStep: build target-specific train/val CSVs
    process_step = ProcessingStep(
        name=f"Process-{t}",
        processor=sklearn_processor,
        inputs=[
            ProcessingInput(
                source=param_input_s3,
                destination="/opt/ml/processing/input/data.csv",
            )
        ],
        outputs=[
            ProcessingOutput(output_name="train", source="/opt/ml/processing/train", destination=proc_train_s3),
            ProcessingOutput(output_name="validation", source="/opt/ml/processing/validation", destination=proc_val_s3),
        ],
        code="preprocess_and_split.py",
        job_arguments=[
            "--input-csv", "/opt/ml/processing/input/data.csv",
            "--target-col", t,
            "--feature-cols", ",".join(INPUT_FEATURES),
            "--val-frac", param_val_frac,
            "--out-train", "/opt/ml/processing/train",
            "--out-val", "/opt/ml/processing/validation",
        ],
    )

    steps.append(process_step)

    # 2) AutoMLStep (Autopilot) for this target
    automl = AutoML(
        role=role,
        target_attribute_name=t,
        problem_type="MulticlassClassification",
        objective_metric_name="Accuracy",
        max_candidates=param_max_candidates,
        sagemaker_session=pipeline_session,
        output_path=automl_out_s3,
    )

    automl_step = AutoMLStep(
        name=f"AutoML-{t}",
        automl=automl,
        inputs=[
            sagemaker.automl.automl.InputDataConfig(
                data_source=process_step.properties.ProcessingOutputConfig.Outputs["train"].S3Output.S3Uri,
                compression_type="None",
                content_type="text/csv",
                channel_type="training",
            ),
            sagemaker.automl.automl.InputDataConfig(
                data_source=process_step.properties.ProcessingOutputConfig.Outputs["validation"].S3Output.S3Uri,
                compression_type="None",
                content_type="text/csv",
                channel_type="validation",
            ),
        ],
    )

    # Ensure AutoML waits for preprocessing
    automl_step.add_depends_on([process_step])
    steps.append(automl_step)

pipeline = Pipeline(
    name=PIPELINE_NAME,
    parameters=[param_input_s3, param_output_base, param_val_frac, param_max_candidates],
    steps=steps,
    sagemaker_session=pipeline_session,
)
