AUTOML_MAX_CANDIDATES = ParameterInteger("AutoMLMaxCandidates", default_value=5)
AUTOML_TOTAL_RUNTIME  = ParameterInteger("AutoMLTotalRuntimeSec", default_value=1800)  # per target

# --------- Step 1: Processing (split) ----------
img = sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1")
script_processor = ScriptProcessor(
    image_uri=img,
    role=role,
    instance_type="ml.m5.xlarge",
    instance_count=1,
    command=["python3"],
    sagemaker_session=pipeline_session,
)

split_step = ProcessingStep(
    name="SplitTrainValidation",
    processor=script_processor,
    inputs=[
        ProcessingInput(source=INPUT_S3, destination="/opt/ml/processing/input")
    ],
    outputs=[
        ProcessingOutput(output_name="train",      source="/opt/ml/processing/output/train"),
        ProcessingOutput(output_name="validation", source="/opt/ml/processing/output/validation"),
    ],
    code="prep_split_multitarget.py",
    job_arguments=[
        "--targets", json.dumps(TARGET_COLS),
        "--input_features", json.dumps(INPUT_FEATURES),
        "--val_frac", "0.2",
        "--random_seed", "42",
        "--mounted_input_dir", "/opt/ml/processing/input",
        "--output_dir", "/opt/ml/processing/output",
        "--min_rows", "50",
    ],
)

train_root_s3 = split_step.properties.ProcessingOutputConfig.Outputs["train"].S3Output.S3Uri
val_root_s3   = split_step.properties.ProcessingOutputConfig.Outputs["validation"].S3Output.S3Uri

# --------- Step 2: AutoML per target (use S3 PREFIXES + validation channel) ----------
automl_steps = []

for tgt in TARGET_COLS:
    tgt_safe = safe_name(tgt.lower(), max_len=22)
    project_safe = safe_name(PROJECT_PREFIX.lower(), max_len=18)

    # IMPORTANT: pass prefixes, not file paths
    train_prefix = Join(on="/", values=[train_root_s3, tgt])       # contains train.csv
    val_prefix   = Join(on="/", values=[val_root_s3, tgt])         # contains validation.csv

    automl_output = f"s3://{BUCKET}/{PROJECT_PREFIX}/autopilot-output/{tgt_safe}/"

    auto_inputs = [
        AutoMLInput(
            inputs=train_prefix,
            channel_type="training",
            content_type="text/csv;header=present",
            target_attribute_name=tgt,
        ),
        AutoMLInput(
            inputs=val_prefix,
            channel_type="validation",
            content_type="text/csv;header=present",
            target_attribute_name=tgt,
        ),
    ]

    automl = AutoML(
        role=role,
        sagemaker_session=pipeline_session,
        target_attribute_name=tgt,
        output_path=automl_output,
        problem_type="MulticlassClassification",
        job_objective={"MetricName": "Accuracy"},
        max_candidates=AUTOML_MAX_CANDIDATES,
        mode="ENSEMBLING",  # required for AutoMLStep
        total_job_runtime_in_seconds=AUTOML_TOTAL_RUNTIME,
        max_runtime_per_training_job_in_seconds=900,
        base_job_name=f"{project_safe}-{tgt_safe}",
    )

    step_args = automl.fit(inputs=auto_inputs)

    step_automl = AutoMLStep(
        name=f"AutoML-{tgt_safe}",
        step_args=step_args,
        depends_on=[split_step],
    )

    automl_steps.append(step_automl)

# --------- Build & upsert the pipeline ----------
pipeline = Pipeline(
    name=safe_name(f"{PROJECT_PREFIX}-train-only", max_len=80),
    parameters=[AUTOML_MAX_CANDIDATES, AUTOML_TOTAL_RUNTIME],
    steps=[split_step] + automl_steps,
    sagemaker_session=pipeline_session,
)

pipeline.upsert(role_arn=role)
print("âœ… Upserted:", pipeline.name)
