%%writefile prep_for_autopilot.py
import argparse
import os
import glob
import json
import pandas as pd
import numpy as np
import csv

def valid_target_mask(series: pd.Series) -> pd.Series:
    s_str = series.astype(str).str.strip()
    missing_values = {"", "nan", "NaN", "none", "None", "null", "NULL"}
    missing = series.isna() | s_str.isin(missing_values)
    return ~missing

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_dir", required=True)
    parser.add_argument("--targets", required=True)           # json list
    parser.add_argument("--input_features", required=True)    # json list
    parser.add_argument("--output_dir", required=True)
    parser.add_argument("--random_state", type=int, default=42)
    args = parser.parse_args()

    targets = json.loads(args.targets)
    feats = json.loads(args.input_features)

    os.makedirs(args.output_dir, exist_ok=True)

    csv_files = glob.glob(os.path.join(args.input_dir, "*.csv"))
    if not csv_files:
        raise FileNotFoundError("No CSV found in input_dir")

    df = pd.read_csv(csv_files[0])
    print(f"[prep] Loaded {csv_files[0]} rows={len(df)}")

    missing_cols = [c for c in feats + targets if c not in df.columns]
    if missing_cols:
        raise ValueError(f"Missing required columns: {missing_cols}")

    # Normalize feature columns (simple + safe; Autopilot handles encodings)
    for c in feats:
        if df[c].dtype == object:
            df[c] = df[c].fillna("").astype(str)
        else:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0)

    rng = np.random.default_rng(args.random_state)

    for tgt in targets:
        print("-" * 60)
        print(f"[prep] Target={tgt}")

        mask = valid_target_mask(df[tgt])
        df_t = df.loc[mask, feats + [tgt]].copy()
        print(f"[prep] Valid rows={len(df_t)} / {len(df)}")

        if len(df_t) == 0:
            print(f"[prep] Skipping {tgt}: no valid rows")
            continue

        # Shuffle once (Autopilot will do its own split)
        idx = np.arange(len(df_t))
        rng.shuffle(idx)
        df_t = df_t.iloc[idx].reset_index(drop=True)

        out_dir = os.path.join(args.output_dir, tgt)
        os.makedirs(out_dir, exist_ok=True)
        out_path = os.path.join(out_dir, "train.csv")

        # Hardened CSV output (no lineterminator for compatibility)
        df_t.to_csv(
            out_path,
            index=False,
            encoding="utf-8",
            quoting=csv.QUOTE_ALL,
            escapechar="\\",
        )

        print(f"[prep] Wrote: {out_path} rows={len(df_t)}")

    print("âœ… Autopilot-prep complete")
