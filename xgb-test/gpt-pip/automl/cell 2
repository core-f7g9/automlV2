%%writefile preprocess_and_split.py
import argparse
import os
import pandas as pd
import numpy as np

def stratified_split_indices(y: pd.Series, val_frac: float, seed: int):
    """
    Returns (train_idx, val_idx) as integer index arrays for a stratified split.

    Rules:
    - For classes with 1 row: keep in TRAIN (cannot stratify into both).
    - For classes with >= 2 rows: ensure at least 1 in TRAIN and at least 1 in VAL.
    """
    rng = np.random.RandomState(seed)

    # Map label -> positions (0..n-1)
    groups = {}
    for i, label in enumerate(y.tolist()):
        groups.setdefault(label, []).append(i)

    train_idx = []
    val_idx = []

    for label, idxs in groups.items():
        idxs = np.array(idxs, dtype=int)
        rng.shuffle(idxs)

        n = len(idxs)
        if n == 1:
            # Singleton class: must remain in train
            train_idx.extend(idxs.tolist())
            continue

        n_val = int(round(n * val_frac))
        # Ensure at least 1 val and at least 1 train
        n_val = max(1, n_val)
        n_val = min(n_val, n - 1)

        val_part = idxs[:n_val]
        train_part = idxs[n_val:]

        val_idx.extend(val_part.tolist())
        train_idx.extend(train_part.tolist())

    # Shuffle final indices to avoid grouped ordering
    train_idx = np.array(train_idx, dtype=int)
    val_idx = np.array(val_idx, dtype=int)
    rng.shuffle(train_idx)
    rng.shuffle(val_idx)

    return train_idx, val_idx

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input-csv", type=str, required=True)
    parser.add_argument("--target-col", type=str, required=True)
    parser.add_argument("--feature-cols", type=str, required=True)  # comma-separated
    parser.add_argument("--val-frac", type=float, default=0.2)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--out-train", type=str, required=True)
    parser.add_argument("--out-val", type=str, required=True)
    args = parser.parse_args()

    feature_cols = [c.strip() for c in args.feature_cols.split(",") if c.strip()]
    target_col = args.target_col

    df = pd.read_csv(args.input_csv)

    needed = feature_cols + [target_col]
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise ValueError(f"Missing columns in CSV: {missing}")

    df = df[needed].copy()

    # Drop rows with missing target (Autopilot requires target present)
    df = df.dropna(subset=[target_col]).reset_index(drop=True)

    # Fill missing features
    for c in feature_cols:
        if df[c].dtype.kind in ("i", "u", "f"):
            df[c] = df[c].fillna(0)
        else:
            df[c] = df[c].astype("string").fillna("")

    # Stratified split on target
    y = df[target_col]
    train_idx, val_idx = stratified_split_indices(y, val_frac=args.val_frac, seed=args.seed)

    train_df = df.iloc[train_idx]
    val_df = df.iloc[val_idx]

    os.makedirs(args.out_train, exist_ok=True)
    os.makedirs(args.out_val, exist_ok=True)

    train_path = os.path.join(args.out_train, "train.csv")
    val_path = os.path.join(args.out_val, "validation.csv")

    train_df.to_csv(train_path, index=False)
    val_df.to_csv(val_path, index=False)

    # Useful diagnostics
    n_singletons = (y.value_counts() == 1).sum()
    print(f"Rows: {len(df)} | Train: {len(train_df)} | Val: {len(val_df)} | ValFrac: {args.val_frac}")
    print(f"Classes: {y.nunique()} | Singleton classes kept in TRAIN: {n_singletons}")

if __name__ == "__main__":
    main()
