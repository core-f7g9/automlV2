%%writefile repack_for_mme.py
import argparse
import os
import tarfile
import shutil
import glob
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def find_model_tar(tgt_dir):
    # Search for model.tar.gz in the target directory or subdirectories
    candidates = [
        os.path.join(tgt_dir, "model.tar.gz"),
        os.path.join(tgt_dir, "output", "model.tar.gz")
    ]
    candidates.extend(glob.glob(os.path.join(tgt_dir, "**", "model.tar.gz"), recursive=True))
    for c in candidates:
        if os.path.exists(c):
            return c
    return None

def safe_extract(path, dest):
    try:
        with tarfile.open(path, "r:gz") as tar:
            tar.extractall(dest)
        return True
    except Exception as e:
        logger.error("Extraction failed for %s: %s", path, e)
        return False

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--models_dir")
    parser.add_argument("--preprocess_dir")
    parser.add_argument("--output_dir")
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)
    
    # Locate artifacts from the preprocessing step
    preprocess_artifacts = glob.glob(os.path.join(args.preprocess_dir, "labelenc_*.pkl"))
    meta_file = os.path.join(args.preprocess_dir, "preprocess_meta.json")
    inference_script_src = "/opt/ml/processing/code/inference.py"

    # Iterate over every target folder (e.g. DepartmentCode, AccountCode...)
    for tgt in os.listdir(args.models_dir):
        tgt_dir = os.path.join(args.models_dir, tgt)
        if not os.path.isdir(tgt_dir):
            continue

        logger.info("Processing target: %s", tgt)
        model_tar = find_model_tar(tgt_dir)

        if not model_tar:
            logger.warning("No model.tar.gz found for %s", tgt)
            continue

        # Extract the original training output
        extract_dir = os.path.join(tgt_dir, "extract_tmp")
        if os.path.exists(extract_dir):
            shutil.rmtree(extract_dir)
        os.makedirs(extract_dir, exist_ok=True)

        if not safe_extract(model_tar, extract_dir):
            continue

        # Find the actual booster file (usually named 'xgboost-model')
        booster_path = os.path.join(extract_dir, "xgboost-model")
        if not os.path.exists(booster_path):
            logger.error("xgboost-model binary not found inside tar for %s", tgt)
            continue

        # ---------------------------------------------------------
        # BUILD PACKAGE: Standard MME Structure
        # ---------------------------------------------------------
        # /
        # ├── xgboost-model        <-- ROOT (Crucial for MME)
        # └── code/
        #     ├── inference.py
        #     ├── requirements.txt <-- Crucial for sklearn
        #     └── (artifacts...)
        # ---------------------------------------------------------
        
        pkg_root = os.path.join(args.output_dir, f"{tgt}_pkg")
        if os.path.exists(pkg_root):
            shutil.rmtree(pkg_root)
        os.makedirs(pkg_root)
        
        code_dir = os.path.join(pkg_root, "code")
        os.makedirs(code_dir)

        # 1. Move Booster to ROOT
        shutil.copy(booster_path, os.path.join(pkg_root, "xgboost-model"))

        # 2. Move Metadata/Artifacts to CODE directory
        if os.path.exists(os.path.join(extract_dir, "class_map.json")):
            shutil.copy(os.path.join(extract_dir, "class_map.json"), code_dir)

        if os.path.exists(meta_file):
            shutil.copy(meta_file, code_dir)

        for enc in preprocess_artifacts:
            shutil.copy(enc, code_dir)

        # 3. Copy Inference Script
        shutil.copy(inference_script_src, os.path.join(code_dir, "inference.py"))

        # 4. Create requirements.txt (CRITICAL)
        # XGBoost containers do NOT have sklearn installed by default.
        # This forces the endpoint to install it on model load.
        with open(os.path.join(code_dir, "requirements.txt"), "w") as req:
            req.write("scikit-learn\n")
            req.write("joblib\n")
            req.write("scipy\n")

        # 5. Create Final Tar
        out_tar = os.path.join(args.output_dir, f"{tgt}.tar.gz")
        
        with tarfile.open(out_tar, "w:gz") as tar:
            # Add booster at root
            tar.add(os.path.join(pkg_root, "xgboost-model"), arcname="xgboost-model")
            # Add code dir
            tar.add(code_dir, arcname="code")

        logger.info("Packaged %s successfully at %s", tgt, out_tar)

if __name__ == "__main__":
    main()