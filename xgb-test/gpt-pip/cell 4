%%writefile repack_for_mme.py
import argparse
import os
import tarfile
import shutil
import glob


def safe_extract_tar(path, dest):
    if not os.path.exists(path):
        print(f"[WARN] Missing tar file: {path}")
        return False
    try:
        with tarfile.open(path, "r:gz") as tar:
            tar.extractall(dest)
        return True
    except Exception as e:
        print(f"[ERROR] Failed to extract {path}: {e}")
        return False


def find_model_tar(tgt_dir):
    """
    Find model.tar.gz inside SageMaker's output structure.
    """
    candidates = glob.glob(os.path.join(tgt_dir, "**", "model.tar.gz"), recursive=True)
    if candidates:
        return candidates[0]

    fallback = os.path.join(tgt_dir, "model.tar.gz")
    if os.path.exists(fallback):
        return fallback

    return None


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--models_dir")
    parser.add_argument("--preprocess_dir")
    parser.add_argument("--output_dir")
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)

    # preprocessing artifacts
    preprocess_artifacts = glob.glob(os.path.join(args.preprocess_dir, "labelenc_*.pkl"))
    meta_file = os.path.join(args.preprocess_dir, "preprocess_meta.json")

    inference_script = "/opt/ml/processing/code/inference.py"

    packaged = 0

    for tgt in os.listdir(args.models_dir):
        tgt_dir = os.path.join(args.models_dir, tgt)
        if not os.path.isdir(tgt_dir):
            continue

        print(f"\n=== Processing target: {tgt} ===")

        model_tar = find_model_tar(tgt_dir)
        if not model_tar:
            print(f"[ERROR] model.tar.gz not found under {tgt_dir}")
            continue

        print(f"[INFO] Found model archive: {model_tar}")

        extract_dir = os.path.join(tgt_dir, "extracted")
        os.makedirs(extract_dir, exist_ok=True)

        if not safe_extract_tar(model_tar, extract_dir):
            print(f"[ERROR] Could not extract: {model_tar}")
            continue

        # Extracted model artifacts
        xgb_model = os.path.join(extract_dir, "xgboost-model")
        class_map = os.path.join(extract_dir, "class_map.json")

        if not os.path.exists(xgb_model):
            print(f"[ERROR] xgboost-model missing inside model.tar.gz!")
            continue

        if not os.path.exists(class_map):
            print(f"[ERROR] class_map.json missing inside model.tar.gz!")
            continue

        # Build package directory
        pkg_dir = os.path.join(args.output_dir, tgt)
        if os.path.exists(pkg_dir):
            shutil.rmtree(pkg_dir)
        os.makedirs(pkg_dir)

        # ===============================
        # PACKAGE STRUCTURE FIXED HERE
        # ===============================

        # ---- Model folder: ONLY the booster goes here ----
        model_dir = os.path.join(pkg_dir, "model")
        os.makedirs(model_dir, exist_ok=True)
        shutil.copy(xgb_model, os.path.join(model_dir, "xgboost-model"))

        # ---- Code folder: all supporting artifacts ----
        code_dir = os.path.join(pkg_dir, "code")
        os.makedirs(code_dir, exist_ok=True)

        # inference script
        shutil.copy(inference_script, os.path.join(code_dir, "inference.py"))

        # class map
        shutil.copy(class_map, os.path.join(code_dir, "class_map.json"))

        # preprocess metadata
        if os.path.exists(meta_file):
            shutil.copy(meta_file, os.path.join(code_dir, "preprocess_meta.json"))

        # encoders
        for enc in preprocess_artifacts:
            shutil.copy(enc, code_dir)

        # ===============================
        # FINAL TARBALL
        # ===============================
        out_tar = os.path.join(args.output_dir, f"{tgt}.tar.gz")
        with tarfile.open(out_tar, "w:gz") as tar:
            tar.add(pkg_dir, arcname=".")

        print(f"[SUCCESS] Packaged model for {tgt}: {out_tar}")
        packaged += 1

    print(f"\nPacked {packaged} models successfully.")


if __name__ == "__main__":
    main()
