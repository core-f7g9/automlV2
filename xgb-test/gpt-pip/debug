import boto3
import os

BUCKET = sm_sess.default_bucket()
MME_PREFIX = f"{PROJECT_PREFIX}/mme-packaged"

model_key = f"{MME_PREFIX}/DepartmentCode.tar.gz"
local_path = "DepartmentCode.tar.gz"

s3 = boto3.client("s3")
s3.download_file(BUCKET, model_key, local_path)

print("Downloaded:", local_path)

import tarfile

with tarfile.open("DepartmentCode.tar.gz", "r:gz") as tar:
    print("\n=== TAR CONTENTS ===")
    for name in tar.getnames():
        print(name)




import boto3

bucket = BUCKET
model_name = "DepartmentCode.tar.gz"  # <<< change this for other targets
prefix = f"{PROJECT_PREFIX}/mme-packaged"

s3_key = f"{prefix}/{model_name}"

print("Downloading:", s3_key)

s3 = boto3.client("s3")
s3.download_file(bucket, s3_key, model_name)

print("Downloaded:", model_name)

import tarfile, os

model_tar = "DepartmentCode.tar.gz"
extract_dir = "test_model"

# Clean up if folder already exists
if os.path.exists(extract_dir):
    import shutil
    shutil.rmtree(extract_dir)

os.makedirs(extract_dir, exist_ok=True)

with tarfile.open(model_tar, "r:gz") as tar:
    tar.extractall(extract_dir)

print("Extracted to:", extract_dir)

print("Root contents:", os.listdir(extract_dir))
print("Code contents:", os.listdir(os.path.join(extract_dir, "code")))

import json
import sys
import os

# Add the code directory to Python path so inference.py can be imported
code_dir = os.path.join("test_model", "code")
if code_dir not in sys.path:
    sys.path.append(code_dir)

# Import inference
import inference

# Load artifacts (this calls model_fn inside inference.py)
artifacts = inference.model_fn("test_model")

# Prepare a test row (modify the fields to match your dataset)
test_payload = {
    "VendorName": "OfficeMax Inc",
    "LineDescription": "Black swivel chair with ergonomic back support",
    "ClubNumber": 123
}

# Run prediction
result = inference.predict_fn(test_payload, artifacts)

print(json.dumps(result, indent=2))






import sagemaker
import boto3

runtime = boto3.client("sagemaker-runtime")
sm = boto3.client("sagemaker")

bucket = BUCKET
model_key = f"{PROJECT_PREFIX}/mme-packaged/DepartmentCode.tar.gz"

model_name = "deptcode-single-model"
endpoint_config_name = "deptcode-single-model-config"
endpoint_name = "deptcode-single-model-endpoint"

print("S3 model path:", f"s3://{bucket}/{model_key}")


from sagemaker import image_uris

region = boto3.Session().region_name
image_uri = image_uris.retrieve("xgboost", region, version="1.5-1")

sm.create_model(
    ModelName=model_name,
    PrimaryContainer={
        "Image": image_uri,
        "ModelDataUrl": f"s3://{bucket}/{model_key}"
    },
    ExecutionRoleArn=role
)

print("Model created.")


sm.create_endpoint_config(
    EndpointConfigName=endpoint_config_name,
    ProductionVariants=[
        {
            "VariantName": "AllTraffic",
            "ModelName": model_name,
            "InitialInstanceCount": 1,
            "InstanceType": "ml.m5.large"
        }
    ]
)

print("Endpoint config created.")


sm.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=endpoint_config_name
)

print("Creating endpointâ€¦")
