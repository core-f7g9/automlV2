# ============================
# Cell 6 ‚Äî FINAL WORKING VERSION
# (LIBSVM + XGBoost + Dynamic Preprocess Paths + Valid Join)
# ============================

import os
import json
import sagemaker
from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput
from sagemaker.workflow.steps import ProcessingStep, TrainingStep
from sagemaker.xgboost.estimator import XGBoost
from sagemaker.inputs import TrainingInput
from sagemaker.workflow.pipeline_context import PipelineSession
from sagemaker.workflow.pipeline import Pipeline
from sagemaker.workflow.functions import Join

pipeline_session = PipelineSession()

# -------------------------------
# PREPROCESSING STEP
# -------------------------------
processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1
)

preprocess_output = f"{PROJECT_NAME}/processing" if "PROJECT_NAME" in globals() else f"{PROJECT_PREFIX}/processing"

step_preprocess = ProcessingStep(
    name="PreprocessData",
    processor=processor,
    inputs=[
        ProcessingInput(
            input_name="raw_data",
            source=INPUT_S3,
            destination="/opt/ml/processing/input"
        )
    ],
    outputs=[
        ProcessingOutput(
            output_name="proc_output",
            source="/opt/ml/processing/output",
            destination=f"s3://{BUCKET}/{preprocess_output}"
        )
    ],
    code="preprocess.py",
    job_arguments=[
        "--input_dir", "/opt/ml/processing/input",
        "--targets", json.dumps(TARGET_COLS),
        "--input_features", json.dumps(INPUT_FEATURES),
        "--output_dir", "/opt/ml/processing/output",
        "--tfidf_max_features", "2000",
    ]
)

# This is the Pipeline Property for the preprocess output S3 URI
proc_uri = step_preprocess.properties.ProcessingOutputConfig.Outputs["proc_output"].S3Output.S3Uri

# -------------------------------
# TRAINING STEPS (LIBSVM + XGBoost)
# -------------------------------
models_output = f"{PROJECT_NAME}/trained-models" if "PROJECT_NAME" in globals() else f"{PROJECT_PREFIX}/trained-models"
train_steps = {}

for tgt in TARGET_COLS:

    estimator = XGBoost(
        entry_point="train.py",
        framework_version="1.5-1",
        instance_type="ml.m5.xlarge",
        instance_count=1,
        role=role,
        output_path=f"s3://{BUCKET}/{models_output}/{tgt}",
        base_job_name=f"xgb-{tgt}"
    )

    # --------------------------
    # ‚≠ê FIXED: Valid S3 paths using Join()
    # No Python string ops, no rstrip(), fully Pipeline-safe
    # --------------------------
    train_path = Join(
        on="/",
        values=[proc_uri, tgt, "train.libsvm"]
    )

    val_path = Join(
        on="/",
        values=[proc_uri, tgt, "val.libsvm"]
    )

    # --------------------------
    # TRAIN ‚Äî MUST use "train" and "validation" channels
    # --------------------------
    step_train = TrainingStep(
        name=f"Train_{tgt}",
        estimator=estimator,
        inputs={
            "train": TrainingInput(
                s3_data=train_path,
                content_type="text/libsvm"
            ),
            "validation": TrainingInput(
                s3_data=val_path,
                content_type="text/libsvm"
            )
        }
    )

    train_steps[tgt] = step_train

# -------------------------------
# REPACK STEP (fixed)
# -------------------------------
mme_output = f"{PROJECT_NAME}/mme-packaged" if "PROJECT_NAME" in globals() else f"{PROJECT_PREFIX}/mme-packaged"

repack_processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1
)

step_repack = ProcessingStep(
    name="RepackModelsForMME",
    processor=repack_processor,
    inputs=[
        ProcessingInput(
            input_name="models_dir",
            source=f"s3://{BUCKET}/{models_output}",
            destination="/opt/ml/processing/models"
        ),
        ProcessingInput(
            input_name="preprocess_dir",
            source=proc_uri,                      # the preprocess output
            destination="/opt/ml/processing/preprocess"
        ),
        ProcessingInput(
            input_name="inference_script",
            source="inference.py",
            destination="/opt/ml/processing/code"
        )
    ],
    outputs=[
        ProcessingOutput(
            output_name="mme_models",
            source="/opt/ml/processing/output",
            destination=f"s3://{BUCKET}/{mme_output}"
        )
    ],
    code="repack_for_mme.py",
    job_arguments=[
        "--models_dir", "/opt/ml/processing/models",
        "--preprocess_dir", "/opt/ml/processing/preprocess",
        "--output_dir", "/opt/ml/processing/output"
    ],
    depends_on=list(train_steps.values())
)

# -------------------------------
# PIPELINE DEFINITION
# -------------------------------
pipeline = Pipeline(
    name="MultiTargetXGBPipeline-LIBSVM",
    steps=[step_preprocess] + list(train_steps.values()) + [step_repack],
    sagemaker_session=pipeline_session
)

pipeline.upsert(role_arn=role)
print("üéâ FINAL PIPELINE CREATED SUCCESSFULLY!")
