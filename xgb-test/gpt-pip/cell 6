# ============================
# Cell 6 â€” Build SageMaker Pipeline
# ============================

import os
import json
from sagemaker.workflow.steps import ProcessingStep, TrainingStep
from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput
from sagemaker.xgboost.estimator import XGBoost
from sagemaker.workflow.model_step import ModelStep
from sagemaker.workflow.pipeline import Pipeline
from sagemaker.model import Model
from sagemaker.workflow.properties import PropertyFile
from sagemaker.inputs import TrainingInput

# ---------- PARAMETERS ----------
preprocess_script = "preprocess.py"
train_script = "train.py"
repack_script = "repack_for_mme.py"
inference_script = "inference.py"

targets_json = json.dumps(TARGET_COLS)

preprocess_output = f"{PROJECT_PREFIX}/processing"
models_output = f"{PROJECT_PREFIX}/trained-models"
mme_output = f"{PROJECT_PREFIX}/mme-packaged"

# ---------- PREPROCESSING STEP ----------
processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1
)

step_preprocess = ProcessingStep(
    name="PreprocessData",
    processor=processor,
    inputs=[
        ProcessingInput(
            input_name="raw_data",
            source=INPUT_S3,
            destination="/opt/ml/processing/input"
        )
    ],
    outputs=[
        ProcessingOutput(output_name="proc_output", source="/opt/ml/processing/output", destination=f"s3://{BUCKET}/{preprocess_output}")
    ],
    code=preprocess_script,
    job_arguments=[
        "--input_csv", "/opt/ml/processing/input/data.csv",
        "--targets", targets_json,
        "--output_dir", "/opt/ml/processing/output",
        "--tfidf_max_features", "5000"
    ]
)

# ---------- TRAINING STEPS (ONE PER TARGET) ----------
xgb_image = sagemaker.image_uris.retrieve("xgboost", region, version="1.5-1")

train_steps = {}
for tgt in TARGET_COLS:
    train_estimator = XGBoost(
        entry_point=train_script,
        framework_version="1.5-1",
        instance_type="ml.m5.xlarge",
        instance_count=1,
        role=role,
        output_path=f"s3://{BUCKET}/{models_output}/{tgt}",
        hyperparameters={}
    )

    step_train = TrainingStep(
        name=f"Train_{tgt}",
        estimator=train_estimator,
        inputs={
            "train": TrainingInput(
                s3_data=f"s3://{BUCKET}/{preprocess_output}/{tgt}/train.csv",
                content_type="text/csv"
            ),
            "val": TrainingInput(
                s3_data=f"s3://{BUCKET}/{preprocess_output}/{tgt}/val.csv",
                content_type="text/csv"
            )
        },
        job_arguments=[
            "--train_csv", "/opt/ml/input/data/train/train.csv",
            "--val_csv", "/opt/ml/input/data/val/val.csv",
            "--model_dir", "/opt/ml/model"
        ]
    )

    train_steps[tgt] = step_train


# ---------- REPACK STEP (MME PACKAGING) ----------
repack_processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1
)

step_repack = ProcessingStep(
    name="RepackModelsForMME",
    processor=repack_processor,
    inputs=[
        ProcessingInput(
            input_name="models_dir",
            source=f"s3://{BUCKET}/{models_output}",
            destination="/opt/ml/processing/models"
        ),
        ProcessingInput(
            input_name="preprocess_dir",
            source=f"s3://{BUCKET}/{preprocess_output}",
            destination="/opt/ml/processing/preprocess"
        ),
        ProcessingInput(
            input_name="inference_script",
            source=inference_script,
            destination="/opt/ml/processing/code"
        )
    ],
    outputs=[
        ProcessingOutput(
            output_name="mme_models",
            source="/opt/ml/processing/output",
            destination=f"s3://{BUCKET}/{mme_output}"
        )
    ],
    code=repack_script,
    job_arguments=[
        "--models_dir", "/opt/ml/processing/models",
        "--preprocess_dir", "/opt/ml/processing/preprocess",
        "--output_dir", "/opt/ml/processing/output"
    ]
)

# ---------- MODEL STEP (CREATE MME MODEL) ----------
mme_model = Model(
    model_data=f"s3://{BUCKET}/{mme_output}",
    role=role,
    image_uri=xgb_image,
    mode="MultiModel"
)

step_model = ModelStep(
    name="CreateMMEModel",
    model=mme_model
)

# ---------- BUILD PIPELINE ----------
pipeline = Pipeline(
    name="MultiTargetXGBPipeline",
    parameters=[],
    steps=[step_preprocess] + list(train_steps.values()) + [step_repack, step_model],
    sagemaker_session=pipeline_session
)

pipeline.upsert(role_arn=role)

print("Pipeline created successfully.")
