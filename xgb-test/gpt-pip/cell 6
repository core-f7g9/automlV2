# ============================
# Cell 6 â€” Fully Connected SageMaker Pipeline (Corrected with Join)
# ============================

import os
import json
import sagemaker
from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput
from sagemaker.workflow.steps import ProcessingStep, TrainingStep
from sagemaker.xgboost.estimator import XGBoost
from sagemaker.inputs import TrainingInput
from sagemaker.workflow.pipeline import Pipeline
from sagemaker.workflow.pipeline_context import PipelineSession
from sagemaker.multidatamodel import MultiDataModel
from sagemaker.workflow.model_step import ModelStep
from sagemaker.workflow.functions import Join

pipeline_session = PipelineSession()

# --------------------------------------------------
# PREPROCESSING STEP
# --------------------------------------------------
processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1
)

preprocess_output = f"{PROJECT_PREFIX}/processing"

step_preprocess = ProcessingStep(
    name="PreprocessData",
    processor=processor,
    inputs=[
        ProcessingInput(
            input_name="raw_data",
            source=INPUT_S3,
            destination="/opt/ml/processing/input"
        )
    ],
    outputs=[
        ProcessingOutput(
            output_name="proc_output",
            source="/opt/ml/processing/output",
            destination=f"s3://{BUCKET}/{preprocess_output}"
        )
    ],
    code="preprocess.py",
    job_arguments=[
        "--input_csv", "/opt/ml/processing/input/data.csv",
        "--targets", json.dumps(TARGET_COLS),
        "--output_dir", "/opt/ml/processing/output",
        "--tfidf_max_features", "5000"
    ]
)

# Capture dynamic S3 prefix that preprocess step writes to
preprocess_s3_uri = (
    step_preprocess.properties.ProcessingOutputConfig.Outputs["proc_output"]
    .S3Output.S3Uri
)

# --------------------------------------------------
# TRAINING STEPS (1 PER TARGET)
# --------------------------------------------------
models_output = f"{PROJECT_PREFIX}/trained-models"
train_steps = {}
xgb_image = sagemaker.image_uris.retrieve("xgboost", region, version="1.5-1")

for tgt in TARGET_COLS:

    estimator = XGBoost(
        entry_point="train.py",
        framework_version="1.5-1",
        instance_type="ml.m5.xlarge",
        instance_count=1,
        role=role,
        output_path=f"s3://{BUCKET}/{models_output}/{tgt}",
        base_job_name=f"xgb-{tgt}"
    )

    # Construct dynamic S3 paths using Join()
    train_path = Join(
        on="/",
        values=[preprocess_s3_uri, tgt, "train.csv"]
    )

    val_path = Join(
        on="/",
        values=[preprocess_s3_uri, tgt, "val.csv"]
    )

    step_train = TrainingStep(
        name=f"Train_{tgt}",
        estimator=estimator,
        inputs={
            "train": TrainingInput(s3_data=train_path, content_type="text/csv"),
            "val":   TrainingInput(s3_data=val_path,   content_type="text/csv")
        }
    )

    train_steps[tgt] = step_train

# --------------------------------------------------
# REPACK STEP â€” MUST WAIT FOR ALL TRAINING STEPS
# --------------------------------------------------
mme_output = f"{PROJECT_PREFIX}/mme-packaged"

repack_processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region, version="1.2-1"),
    role=role,
    command=["python3"],
    instance_type="ml.m5.xlarge",
    instance_count=1
)

# Collect ALL model artifacts dynamically
all_model_artifacts = [
    train_steps[tgt].properties.ModelArtifacts.S3ModelArtifacts
    for tgt in TARGET_COLS
]

step_repack = ProcessingStep(
    name="RepackModelsForMME",
    processor=repack_processor,
    inputs=[
        ProcessingInput(
            input_name="models_dir",
            source=all_model_artifacts,     # dynamic list
            destination="/opt/ml/processing/models"
        ),
        ProcessingInput(
            input_name="preprocess_dir",
            source=preprocess_s3_uri,
            destination="/opt/ml/processing/preprocess"
        ),
        ProcessingInput(
            input_name="inference_script",
            source="inference.py",
            destination="/opt/ml/processing/code"
        )
    ],
    outputs=[
        ProcessingOutput(
            output_name="mme_models",
            source="/opt/ml/processing/output",
            destination=f"s3://{BUCKET}/{mme_output}"
        )
    ],
    code="repack_for_mme.py",
    depends_on=list(train_steps.values())  # <-- WAIT FOR ALL TRAIN STEPS
)

# Capture packaged MME models directory dynamically
repack_s3_uri = (
    step_repack.properties.ProcessingOutputConfig.Outputs["mme_models"]
    .S3Output.S3Uri
)

# --------------------------------------------------
# CREATE MULTI-MODEL MODEL â€” MUST WAIT FOR REPACK
# --------------------------------------------------
mme_model = MultiDataModel(
    name="multi-target-xgb-mme",
    model_data_prefix=repack_s3_uri,  # dynamic URI
    image_uri=xgb_image,
    role=role,
    sagemaker_session=pipeline_session,
)

step_model = ModelStep(
    name="CreateMMEModel",
    step_args=mme_model.create(
        instance_type="ml.m5.xlarge"
    )
)

# --------------------------------------------------
# FINAL CONNECTED PIPELINE
# --------------------------------------------------
pipeline = Pipeline(
    name="MultiTargetXGBPipeline",
    steps=[step_preprocess] + list(train_steps.values()) + [step_repack, step_model],
    sagemaker_session=pipeline_session
)

pipeline.upsert(role_arn=role)
print("ðŸŽ‰ Fully Connected Pipeline (Join-Fixed) Created Successfully!")
