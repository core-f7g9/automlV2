import sagemaker
from sagemaker.processing import ScriptProcessor, ProcessingOutput
from sagemaker.workflow.steps import ProcessingStep
from sagemaker.workflow.functions import Join

processor = ScriptProcessor(
    image_uri=sagemaker.image_uris.retrieve("sklearn", region=region, version="1.2-1"),
    command=["python3"],
    role=role,
    instance_count=1,
    instance_type="ml.m5.xlarge",
    sagemaker_session=pipeline_session,
)

TARGET_LIST = ["DepartmentCode", "AccountCode", "SubAccountCode", "LocationCode"]

processing_outputs = [
    ProcessingOutput(
        output_name="manifest",
        source="/opt/ml/processing/output/manifest",  # directory (NOT a file)
        destination=Join(on="/", values=[p_artifacts_root, p_project, "prepared", "manifest"]),
    )
]

for t in TARGET_LIST:
    processing_outputs.append(
        ProcessingOutput(
            output_name=f"train_{t}",
            source=f"/opt/ml/processing/output/{t}",  # directory containing train.csv
            destination=Join(on="/", values=[p_artifacts_root, p_project, "prepared", t]),
        )
    )

prep_step = ProcessingStep(
    name="PreparePerTargetDatasets",
    processor=processor,
    code="preprocess_targets.py",
    env={
        "INPUT_S3_URI": p_input_s3,
        "TARGET_COLS": p_targets,
        "INPUT_FEATURES": p_features,
        "OUTPUT_DIR": "/opt/ml/processing/output",
    },
    outputs=processing_outputs,
)
