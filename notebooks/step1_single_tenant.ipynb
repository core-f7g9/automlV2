{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91b3b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs: Define AWS region and resource identifiers.\n",
    "import time, boto3\n",
    "region       = boto3.Session().region_name  # use current region\n",
    "bucket       = \"your-s3-bucket\"             # S3 bucket for input/output\n",
    "train_key    = \"data/your-training.csv\"     # S3 key of training CSV (with header)\n",
    "target_col   = \"target\"                     # Name of the target column in CSV\n",
    "problem_type = \"BinaryClassification\"       # or 'MulticlassClassification' / 'Regression'\n",
    "instance_type = \"ml.m5.large\"               # instance type for endpoint\n",
    "\n",
    "# AutoML job configuration (AutoML V2)\n",
    "auto_ml_job_name = f\"autopilot-{int(time.time())}\"  # unique job name with timestamp\n",
    "s3_train_path = f\"s3://{bucket}/{train_key}\"\n",
    "s3_output_path = f\"s3://{bucket}/autopilot-output/{auto_ml_job_name}\"\n",
    "\n",
    "# Prepare optional feature whitelist: list all feature columns (excluding target).\n",
    "# This assumes we have the header; here we demonstrate creating the JSON spec.\n",
    "import io\n",
    "import csv\n",
    "# Download the header row from S3\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=train_key)\n",
    "header = next(csv.reader(io.TextIOWrapper(obj[\"Body\"])))\n",
    "feature_columns = [col for col in header if col != target_col]\n",
    "# Upload FeatureSpecification JSON to S3\n",
    "feature_spec = {\"FeatureAttributeNames\": feature_columns}\n",
    "feat_spec_key = f\"{auto_ml_job_name}/features.json\"\n",
    "s3.put_object(Bucket=bucket, Key=feat_spec_key, Body=str(feature_spec).encode())\n",
    "feature_spec_uri = f\"s3://{bucket}/{feat_spec_key}\"\n",
    "\n",
    "# Launch SageMaker Autopilot (AutoML V2) job\n",
    "sm = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm.create_auto_ml_job_v2(\n",
    "    AutoMLJobName=auto_ml_job_name,\n",
    "    AutoMLJobInputDataConfig=[{\n",
    "        \"ChannelType\": \"training\",\n",
    "        \"ContentType\": \"text/csv;header=present\",\n",
    "        \"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": s3_train_path}}\n",
    "    }],\n",
    "    OutputDataConfig={\"S3OutputPath\": s3_output_path},\n",
    "    RoleArn=boto3.client(\"sts\").get_caller_identity()[\"Arn\"],  # assuming role is current identity\n",
    "    AutoMLProblemTypeConfig={\n",
    "        \"TabularJobConfig\": {\n",
    "            \"TargetAttributeName\": target_col,\n",
    "            \"ProblemType\": problem_type,\n",
    "            # Let Mode default to AUTO; you could set \"ENSEMBLING\" or \"HYPERPARAMETER_TUNING\" if desired.\n",
    "            \"FeatureSpecificationS3Uri\": feature_spec_uri,\n",
    "            \"CompletionCriteria\": {\"MaxCandidates\": 3}  # limit to 3 model candidates for speed/cost\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Started AutoML job: {auto_ml_job_name}\")\n",
    "\n",
    "# Poll for job completion (this may take time depending on data size and MaxCandidates)\n",
    "describe_response = None\n",
    "while True:\n",
    "    describe_response = sm.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)\n",
    "    status = describe_response[\"AutoMLJobStatus\"]\n",
    "    sec_status = describe_response.get(\"AutoMLJobSecondaryStatus\")\n",
    "    print(f\"Status: {status} - {sec_status}\")\n",
    "    if status in [\"Completed\", \"Failed\", \"Stopped\"]:\n",
    "        break\n",
    "    time.sleep(60)\n",
    "\n",
    "if status != \"Completed\":\n",
    "    raise RuntimeError(f\"AutoML job did not complete successfully (status: {status})\")\n",
    "\n",
    "# Get best candidate and create a SageMaker model from it\n",
    "# (Autopilot V2 returns the best candidate's container definitions for inference)\n",
    "best_candidate = describe_response[\"BestCandidate\"]\n",
    "inf_containers = best_candidate[\"InferenceContainers\"]\n",
    "model_name = f\"{auto_ml_job_name}-model\"\n",
    "sm.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=inf_containers,            # Use all containers from the best candidate:contentReference[oaicite:6]{index=6}\n",
    "    ExecutionRoleArn=boto3.client(\"iam\").get_user()[\"User\"].arn  # assuming the current IAM user/role ARN\n",
    ")\n",
    "\n",
    "# Create or update endpoint configuration and endpoint\n",
    "endpoint_config_name = f\"{auto_ml_job_name}-config\"\n",
    "sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        \"VariantName\": \"AllTraffic\",\n",
    "        \"ModelName\": model_name,\n",
    "        \"InstanceType\": instance_type,\n",
    "        \"InitialInstanceCount\": 1\n",
    "    }]\n",
    ")\n",
    "endpoint_name = \"autopilot-poc-endpoint\"  # stable endpoint name for this PoC\n",
    "try:\n",
    "    # If endpoint exists, update it with new config; otherwise create a new endpoint\n",
    "    sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"Updating existing endpoint: {endpoint_name}\")\n",
    "    sm.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "except sm.exceptions.ClientError:\n",
    "    print(f\"Creating new endpoint: {endpoint_name}\")\n",
    "    sm.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Wait for endpoint to be in service\n",
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint {endpoint_name} is InService\")\n",
    "\n",
    "# Invoke the endpoint with a sample from the CSV (excluding the target column)\n",
    "import base64\n",
    "runtime = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "# Take the first data row (after header) from the training CSV for a test prediction\n",
    "lines = obj[\"Body\"].read().decode().splitlines()\n",
    "if len(lines) > 1:\n",
    "    sample = lines[1].split(\",\")\n",
    "    # Remove the target value from the sample if present\n",
    "    if target_col in header:\n",
    "        target_index = header.index(target_col)\n",
    "        sample.pop(target_index)\n",
    "    payload = \",\".join(sample)\n",
    "else:\n",
    "    payload = \"\"  # fallback if no data\n",
    "if payload:\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                       ContentType=\"text/csv\",\n",
    "                                       Body=payload)\n",
    "    prediction = response[\"Body\"].read().decode()\n",
    "    print(\"Sample prediction:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
